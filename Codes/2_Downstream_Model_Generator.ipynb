{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Downstream Model Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df6b0cfad0f44bcfa3e70baa957d447d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12b1df59d0534e379d5bdb317e26aa27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aab9e8a42ab345c4b1be6302e4294b68",
              "IPY_MODEL_9a7f9894e4424097b6a6cef08d6247b7",
              "IPY_MODEL_ae0517b96e1f4b4391ccefbf663a3c1b"
            ]
          }
        },
        "12b1df59d0534e379d5bdb317e26aa27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aab9e8a42ab345c4b1be6302e4294b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ddccc5f8aaa40f0aa5a48b09caf98df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff09f90432374c01b0094465ec937568"
          }
        },
        "9a7f9894e4424097b6a6cef08d6247b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_facbdc7bbcc0470e96d7b2cf6936588e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c3aa8fb47a848d9b2ae9a3e8f5bfef1"
          }
        },
        "ae0517b96e1f4b4391ccefbf663a3c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1878ab48648e4104910c67cb19129522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 2.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66a9b77ecb9245e4b606c614126b9306"
          }
        },
        "9ddccc5f8aaa40f0aa5a48b09caf98df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff09f90432374c01b0094465ec937568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "facbdc7bbcc0470e96d7b2cf6936588e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c3aa8fb47a848d9b2ae9a3e8f5bfef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1878ab48648e4104910c67cb19129522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66a9b77ecb9245e4b606c614126b9306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0d87ea0dbb24df4980108ab6f303f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8b21a14eb9d455297379f11545131b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fab0a80989f4d3cb4d579e3faca97ee",
              "IPY_MODEL_588c8e77f097476fa035918976a1a268",
              "IPY_MODEL_ba905d4190e149b3bb32c96c39391a71"
            ]
          }
        },
        "f8b21a14eb9d455297379f11545131b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fab0a80989f4d3cb4d579e3faca97ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2ae12b2a57c432a91457beac450c1c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5141320bc955484d82358afba3026084"
          }
        },
        "588c8e77f097476fa035918976a1a268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf5b67efda5d45deae2929c64f4b0e1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d122a815a8cd46d5a60c035252d93032"
          }
        },
        "ba905d4190e149b3bb32c96c39391a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f1fa51cd04c4dd0b12da082f5284308",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 785B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a9b8c5dfb9241f092579d5cf947414d"
          }
        },
        "c2ae12b2a57c432a91457beac450c1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5141320bc955484d82358afba3026084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf5b67efda5d45deae2929c64f4b0e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d122a815a8cd46d5a60c035252d93032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f1fa51cd04c4dd0b12da082f5284308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a9b8c5dfb9241f092579d5cf947414d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff34d39912294366b777a93bf1ca706e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dbec93f98f5f41b190fc87394a19767f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5349dcc857848c2b641818e46f1e6ac",
              "IPY_MODEL_dc8b5a20afa04f82b7f94369021f8545",
              "IPY_MODEL_9687286be11440d9a7d4dac65176600e"
            ]
          }
        },
        "dbec93f98f5f41b190fc87394a19767f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5349dcc857848c2b641818e46f1e6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_742a6c4398de4a06acdc7fc55c8d183d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fa84e0b4daf46f2ab8dd5d3138e37e3"
          }
        },
        "dc8b5a20afa04f82b7f94369021f8545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01e5caf726a643ffa73d9bcbd436dd83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2641f8d64d2447d9af46defd5c789907"
          }
        },
        "9687286be11440d9a7d4dac65176600e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e87bf4c3f0443caae581ee9e92c95db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 1.73MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1f6d938bec743179ba87eb809187178"
          }
        },
        "742a6c4398de4a06acdc7fc55c8d183d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fa84e0b4daf46f2ab8dd5d3138e37e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01e5caf726a643ffa73d9bcbd436dd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2641f8d64d2447d9af46defd5c789907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e87bf4c3f0443caae581ee9e92c95db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1f6d938bec743179ba87eb809187178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c6c373c77944af7824124d8f19a3b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4491751d306a45c4b0d7b787932f019e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86bf33edc5d749c58124b379d21a6b26",
              "IPY_MODEL_27535791e50c4f56a2e031eecdb1d79f",
              "IPY_MODEL_1f54350cfae74cdfbbf3667eb15b53a6"
            ]
          }
        },
        "4491751d306a45c4b0d7b787932f019e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86bf33edc5d749c58124b379d21a6b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d00191a511a4e7895403e01771fb17c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0ac738d2bc14965bd4a13814c754223"
          }
        },
        "27535791e50c4f56a2e031eecdb1d79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c0a8e7bb09b4edf8235987357e66714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0fa088de3454b64835e48c4d6d2f798"
          }
        },
        "1f54350cfae74cdfbbf3667eb15b53a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5954eb2747b4769a4304dedee0b6700",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 17.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d28b43cd9c164af7b0310f13d14d4661"
          }
        },
        "9d00191a511a4e7895403e01771fb17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0ac738d2bc14965bd4a13814c754223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c0a8e7bb09b4edf8235987357e66714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0fa088de3454b64835e48c4d6d2f798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5954eb2747b4769a4304dedee0b6700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d28b43cd9c164af7b0310f13d14d4661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26ccc84d55734e449b7cdf9d1fcefac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92e660bd8599444aa376db1f2b7146df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86dc15c3616449959aed4a7cb4e44c09",
              "IPY_MODEL_72bd2cb3ec5740eba45666d56e1121de",
              "IPY_MODEL_e74d850fa92e451db37a6f76ba58cfc8"
            ]
          }
        },
        "92e660bd8599444aa376db1f2b7146df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86dc15c3616449959aed4a7cb4e44c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c28c52f254b48d78eb902c39092add8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d6b053f2de544fd8891336f4bcc380c"
          }
        },
        "72bd2cb3ec5740eba45666d56e1121de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9bc8c3e5ec3a4fe3914ef4811ef5337d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45144515d7514432b03c702d7a2f536d"
          }
        },
        "e74d850fa92e451db37a6f76ba58cfc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ba3a7be32f64f8a8339b2ed961a9458",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:11&lt;00:00, 39.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ca9640408944250b907e6350ddbc1b5"
          }
        },
        "6c28c52f254b48d78eb902c39092add8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d6b053f2de544fd8891336f4bcc380c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bc8c3e5ec3a4fe3914ef4811ef5337d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45144515d7514432b03c702d7a2f536d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ba3a7be32f64f8a8339b2ed961a9458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ca9640408944250b907e6350ddbc1b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvV7Uo69gXKx"
      },
      "source": [
        "Initialization Google Drive Configuration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbwf8ZQ4msnh",
        "outputId": "98b7c0f6-d1a3-446c-fe62-b57d3cc99d5e"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaNmxQExPePh"
      },
      "source": [
        "# 2. Downstream Model Generator\n",
        "\n",
        "**Created By:**  Jirarote Jirasirikul\n",
        "\n",
        "**Monash University (Melbourne) Australia** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R7p3ovrgzrW"
      },
      "source": [
        "## Import Library\n",
        "\n",
        "All Library and File Path will be added here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF5f8SlWm1pO"
      },
      "source": [
        "# Standard Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
        "from sklearn.metrics import precision_recall_fscore_support,accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler    \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "import json \n",
        "\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVHZHjgso3hK",
        "outputId": "979786a6-77b9-4d19-f4ac-a68b6843631a"
      },
      "source": [
        "# BERT Transformer Library\n",
        "!pip install transformers\n",
        "import transformers as ppb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IefVNs1t6126"
      },
      "source": [
        "## Check Available Device (CPU/GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-y7tvn3W56D",
        "outputId": "148a7039-863a-4972-fcc4-c2db4458c577"
      },
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    DEVICE_AVAILABLE = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    DEVICE_AVAILABLE = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl8gzTAeEkum"
      },
      "source": [
        "## Utilities Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgAJRyveSxKi"
      },
      "source": [
        "# # MY GLOBAL FUNCTION - \n",
        "\n",
        "ENABLE_LOGS = 1\n",
        "def print_log(*arg, log_type=\"Info\"):\n",
        "    global ENABLE_LOGS\n",
        "    if(ENABLE_LOGS==1 or log_type!=\"Info\"): \n",
        "        print(\"[\"+log_type+\"]\",\" \".join(str(x) for x in arg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvG2zw2Qhzn2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "##BERT Text Representation\n",
        "\n",
        "Transform Language Model\n",
        "\n",
        "When using BERT, technically we are transforming our sentence into a vector that represent each sentence. The process is call Language Model a representation of each word. \n",
        "\n",
        "BERT add [CLS] token infront of each sentence. This token representation vector could later be use for Classification as it contain the sentence representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCg6mhF8hzn2"
      },
      "source": [
        "### Class my_BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRKtW4pvksLZ"
      },
      "source": [
        "# BERT weight Options \n",
        "# - 'distilbert-base-uncased'\n",
        "# - 'bert-base-uncased'\n",
        "# - 'dmis-lab/biobert-base-cased-v1.1'\n",
        "# - 'dmis-lab/biobert-v1.1' : Data Mining and Information Systems Lab, Korea University's picture Updated May 19 • 41k\n",
        "# - 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmAwnsOFXd8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250,
          "referenced_widgets": [
            "df6b0cfad0f44bcfa3e70baa957d447d",
            "12b1df59d0534e379d5bdb317e26aa27",
            "aab9e8a42ab345c4b1be6302e4294b68",
            "9a7f9894e4424097b6a6cef08d6247b7",
            "ae0517b96e1f4b4391ccefbf663a3c1b",
            "9ddccc5f8aaa40f0aa5a48b09caf98df",
            "ff09f90432374c01b0094465ec937568",
            "facbdc7bbcc0470e96d7b2cf6936588e",
            "5c3aa8fb47a848d9b2ae9a3e8f5bfef1",
            "1878ab48648e4104910c67cb19129522",
            "66a9b77ecb9245e4b606c614126b9306",
            "a0d87ea0dbb24df4980108ab6f303f87",
            "f8b21a14eb9d455297379f11545131b4",
            "3fab0a80989f4d3cb4d579e3faca97ee",
            "588c8e77f097476fa035918976a1a268",
            "ba905d4190e149b3bb32c96c39391a71",
            "c2ae12b2a57c432a91457beac450c1c1",
            "5141320bc955484d82358afba3026084",
            "cf5b67efda5d45deae2929c64f4b0e1b",
            "d122a815a8cd46d5a60c035252d93032",
            "6f1fa51cd04c4dd0b12da082f5284308",
            "0a9b8c5dfb9241f092579d5cf947414d",
            "ff34d39912294366b777a93bf1ca706e",
            "dbec93f98f5f41b190fc87394a19767f",
            "b5349dcc857848c2b641818e46f1e6ac",
            "dc8b5a20afa04f82b7f94369021f8545",
            "9687286be11440d9a7d4dac65176600e",
            "742a6c4398de4a06acdc7fc55c8d183d",
            "4fa84e0b4daf46f2ab8dd5d3138e37e3",
            "01e5caf726a643ffa73d9bcbd436dd83",
            "2641f8d64d2447d9af46defd5c789907",
            "0e87bf4c3f0443caae581ee9e92c95db",
            "c1f6d938bec743179ba87eb809187178",
            "0c6c373c77944af7824124d8f19a3b39",
            "4491751d306a45c4b0d7b787932f019e",
            "86bf33edc5d749c58124b379d21a6b26",
            "27535791e50c4f56a2e031eecdb1d79f",
            "1f54350cfae74cdfbbf3667eb15b53a6",
            "9d00191a511a4e7895403e01771fb17c",
            "b0ac738d2bc14965bd4a13814c754223",
            "5c0a8e7bb09b4edf8235987357e66714",
            "f0fa088de3454b64835e48c4d6d2f798",
            "f5954eb2747b4769a4304dedee0b6700",
            "d28b43cd9c164af7b0310f13d14d4661",
            "26ccc84d55734e449b7cdf9d1fcefac0",
            "92e660bd8599444aa376db1f2b7146df",
            "86dc15c3616449959aed4a7cb4e44c09",
            "72bd2cb3ec5740eba45666d56e1121de",
            "e74d850fa92e451db37a6f76ba58cfc8",
            "6c28c52f254b48d78eb902c39092add8",
            "5d6b053f2de544fd8891336f4bcc380c",
            "9bc8c3e5ec3a4fe3914ef4811ef5337d",
            "45144515d7514432b03c702d7a2f536d",
            "9ba3a7be32f64f8a8339b2ed961a9458",
            "9ca9640408944250b907e6350ddbc1b5"
          ]
        },
        "outputId": "ff623e0d-163b-4af9-e08d-36d19b2fe984"
      },
      "source": [
        "class my_BERT:\n",
        "    ###### Load pretrain BERT Language Model transformer (Otherwise use 'set' to customize)\n",
        "    model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "    # Load pretrained model/tokenizer\n",
        "    bert_tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "    bert_tokenizer.add_special_tokens = True\n",
        "    bert_model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "    PRETRAIN_MAPPING = {'distilbert-base-uncased':'distilbert-base-uncased',\n",
        "                        'bert-base-uncased':'bert-base-uncased',\n",
        "                        'biobert-base-cased':'dmis-lab/biobert-base-cased-v1.1',\n",
        "                        'biobert-base-uncased':'dmis-lab/biobert-v1.1',\n",
        "                        'pubmedbert-base-uncased':'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'}\n",
        "\n",
        "    def __init__(self, df_input,is_transform=False, ENABLE_LOGS = 1):\n",
        "        ## INPUT STRUCTURE (COLUMNS): \n",
        "        ## - 'text' - Required\n",
        "        ## - 'label' - Optional default name is 'label' otherwise need to specific when called\n",
        "\n",
        "        if(is_transform):\n",
        "            self.df = None\n",
        "            self.df_BERT = df_input\n",
        "        else:\n",
        "            self.df = df_input\n",
        "            self.df_BERT = None\n",
        "        self.ENABLE_LOGS = ENABLE_LOGS\n",
        "    \n",
        "    def print_log(self, *arg, log_type=\"Info\"):\n",
        "        if(self.ENABLE_LOGS==1 or log_type!=\"Info\"): \n",
        "            print(\"[\"+log_type+\"]\",\" \".join(str(x) for x in arg))\n",
        "\n",
        "    def bert_tokenize(self, token_length=128):\n",
        "        df_output = self.df.copy()\n",
        "\n",
        "        # BERT Tokenizer + truncate to BERT_MAX_LENGTH\n",
        "        df_output['BERTTokens'] = df_output[\"text\"].apply((lambda x: self.bert_tokenizer.encode(x, add_special_tokens=True,truncation=True,max_length = token_length)))\n",
        "        # df_output['n_tokens0'] = df_output['BERTTokens'].apply(lambda x: len(x)) # Just for verification\n",
        "        temp = df_output['BERTTokens'].apply(lambda x: len(x))\n",
        "        self.print_log(\"Token - Done\",\"( mean/max no. of token:\",round(temp.mean()),temp.max(),\")\")\n",
        "\n",
        "        # Padding tokens to BERT_MAX_LENGTH\n",
        "        df_output['BERTTokens'] = df_output['BERTTokens'].apply(lambda x: x + [0]*(token_length-len(x)))\n",
        "        # df_output['n_tokens'] = df_output['BERTTokens'].apply(lambda x: len(x)) # Just for verification\n",
        "        self.print_log(\"Pad - Done\")\n",
        "\n",
        "        # BERT Mask\n",
        "        df_output['BERTMasks'] = df_output['BERTTokens'].apply(lambda x: [np.where(i != 0, 1, 0) for i in x])\n",
        "        # df_output['n_mask1'] = df_output['BERTMask'].apply(lambda x: sum(x)) # Just for verification\n",
        "        self.print_log(\"Mask - Done\")\n",
        "\n",
        "        return df_output\n",
        "\n",
        "    def run_bert_transform(self, dataloader, device_available = torch.device(\"cpu\")):\n",
        "        all_result = []\n",
        "\n",
        "        self.bert_model.to(device_available)\n",
        "\n",
        "        digit = len(str(len(dataloader)))-1 # Report progress\n",
        "\n",
        "        for step, batch in enumerate(dataloader):\n",
        "            if(step == 0 or (step+1)%(10**digit) == 0 or step == len(dataloader)-1): self.print_log(\"Step:\",step+1,\"/\",len(dataloader))\n",
        "\n",
        "            b_input_ids = batch[0].to(device_available)\n",
        "            b_input_mask = batch[1].to(device_available)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                last_hidden_states = self.bert_model(b_input_ids, attention_mask=b_input_mask)\n",
        "        \n",
        "            \n",
        "            res_features = last_hidden_states[0][:,0,:].cpu().numpy()\n",
        "            all_result.append(res_features)\n",
        "        self.print_log(\"BERT transform - Done\")\n",
        "\n",
        "        return np.vstack(all_result)\n",
        "\n",
        "\n",
        "    def bert_transform(self, device_available = torch.device(\"cpu\"), batch_size = 32, token_length=128):\n",
        "        df_output = self.bert_tokenize(token_length)\n",
        "\n",
        "        # Convert to Tensor\n",
        "        input_tokens = torch.tensor(np.stack(df_output['BERTTokens'].values))\n",
        "        input_masks = torch.tensor(np.stack(df_output['BERTMasks'].values))\n",
        "        # print(input_tokens,input_masks)\n",
        "\n",
        "        # Create the DataLoader for our training set.\n",
        "        input_data = TensorDataset(input_tokens, input_masks)\n",
        "        input_sampler = SequentialSampler(input_data)\n",
        "        input_dataloader = DataLoader(input_data, sampler=input_sampler, batch_size=batch_size)\n",
        "\n",
        "        self.print_log(\"Running BERT Transform on\", str(device_available))\n",
        "        if(str(device_available) == 'cpu'):\n",
        "            self.print_log(\"Running BERT on CPU can take longer time...\",log_type=\"WARNING\")\n",
        "        self.print_log(\"BERT token length:\",token_length)\n",
        "        self.print_log(\"Data size:\",str(len(input_tokens)), \"( Total batch\", str(len(input_dataloader)),'* size',str(batch_size),\")\")\n",
        "        \n",
        "        output_features = self.run_bert_transform(input_dataloader,device_available)\n",
        "        df_output = pd.concat([df_output,pd.DataFrame(output_features.tolist()).add_prefix('feature_')],axis=1)\n",
        "        \n",
        "        self.print_log(\"BERT transformed\", log_type=\"Success\")\n",
        "        self.df_BERT = df_output\n",
        "\n",
        "    def get_features(self):\n",
        "        if(isinstance(self.df_BERT, pd.DataFrame)):\n",
        "            return np.array(self.df_BERT.filter(regex='feature_',axis=1).values)\n",
        "            # return np.array([np.array(xi) for xi in self.df_BERT.BERT_Features.values])\n",
        "        else:\n",
        "            print_log(\"Please run function 'bert_transform' to generate text representation first!\",log_type=\"Error\")\n",
        "\n",
        "    def get_labels(self, list_target = ['label']):\n",
        "        return np.array(self.df_BERT[list_target].values.tolist())\n",
        "\n",
        "    def get_current_bert_model(self):\n",
        "        return self.bert_model.config._name_or_path\n",
        "\n",
        "    def load_pretrain_bert(self, model_name='bert-base-uncased'):\n",
        "        ## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "        self.model_class, self.tokenizer_class, self.pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, self.PRETRAIN_MAPPING[model_name])\n",
        "\n",
        "        # Load pretrained model/tokenizer\n",
        "        self.bert_tokenizer = self.tokenizer_class.from_pretrained(self.pretrained_weights)\n",
        "        self.bert_model = self.model_class.from_pretrained(self.pretrained_weights)\n",
        "\n",
        "    def get_features_df(self,additional_col=[]):\n",
        "        if(isinstance(self.df_BERT, pd.DataFrame)):\n",
        "            return pd.concat([self.df_BERT.filter(regex='feature_',axis=1),self.df_BERT[additional_col]], axis=1)\n",
        "        else:\n",
        "            print_log(\"Please run function 'bert_transform' to generate text representation first!\",log_type=\"Error\")\n",
        "\n",
        "    ### BELOW is an EXTENSION\n",
        "\n",
        "    def extract_hoc_label(self):\n",
        "        try:\n",
        "            LABEL_LIST = ['label_IM', 'label_ID', 'label_CE', 'label_RI', 'label_GS', 'label_GI', 'label_A', 'label_CD', 'label_PS', 'label_TPI']\n",
        "            temp = self.df_BERT['label'].str.split(',').apply(lambda x: [int(i.split('_')[1]) for i in x])\n",
        "            temp_df = pd.DataFrame(temp.tolist())\n",
        "            temp_df.columns = LABEL_LIST\n",
        "            self.df_BERT = pd.concat([self.df_BERT,temp_df], axis=1)\n",
        "            print_log(\"Extract HoC label\",log_type=\"Success\")\n",
        "            return self.df_BERT\n",
        "        except:\n",
        "            print_log(\"Something went wrong\",log_type=\"Error\")\n",
        "        \n",
        "    def class2idx_pubmedqa_label(self,col='label'):\n",
        "        try:\n",
        "            class2idx = {\n",
        "                'no':0,\n",
        "                'maybe':1,\n",
        "                'yes':2\n",
        "            }\n",
        "            # idx2class = {v: k for k, v in class2idx.items()}\n",
        "            self.df_BERT[col].replace(class2idx, inplace=True)\n",
        "            print_log(\"class2idx_pubmedqa_label\",log_type=\"Success\")\n",
        "            return self.df_BERT\n",
        "        except:\n",
        "            print_log(\"Something went wrong\",log_type=\"Error\")\n",
        "\n",
        "    def class2idx_bioasq_label(self,col='label'):\n",
        "        try:\n",
        "            class2idx = {\n",
        "                'no':0,\n",
        "                'yes':1\n",
        "            }\n",
        "            # idx2class = {v: k for k, v in class2idx.items()}\n",
        "            self.df_BERT[col].replace(class2idx, inplace=True)\n",
        "            print_log(\"class2idx_bioasq_label\",log_type=\"Success\")\n",
        "            return self.df_BERT\n",
        "        except:\n",
        "            print_log(\"Something went wrong\",log_type=\"Error\")\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df6b0cfad0f44bcfa3e70baa957d447d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0d87ea0dbb24df4980108ab6f303f87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff34d39912294366b777a93bf1ca706e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c6c373c77944af7824124d8f19a3b39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26ccc84d55734e449b7cdf9d1fcefac0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpYooIbJ2QXc"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Downstream Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDbpq6ueEIKB"
      },
      "source": [
        "### Class: my_downstream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPVaJqlpFb06"
      },
      "source": [
        "Dataset training hyperparameter in BLURB Paper\n",
        "*   learning_rate = [1e-5, 3e-3, 5e-5]\n",
        "*   batch_size = (16,32)\n",
        "*   epoch_number = 2~60\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyArDs-sUx4T"
      },
      "source": [
        "class LinearLayer(torch.nn.Module):\n",
        "    def __init__(self, D_in, D_out):\n",
        "        super(LinearLayer, self).__init__()\n",
        "\n",
        "        self.linear = torch.nn.Linear(D_in, D_out)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        output = self.linear(x)\n",
        "        # output = self.dropout(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2dMv6BPoA4C"
      },
      "source": [
        "class MulticlassClassification(torch.nn.Module):\n",
        "    def __init__(self, num_feature, num_class):\n",
        "        super(MulticlassClassification, self).__init__()\n",
        "        \n",
        "        self.layer_1 = nn.Linear(num_feature, 512)\n",
        "        self.layer_2 = nn.Linear(512, 128)\n",
        "        self.layer_3 = nn.Linear(128, 64)\n",
        "        self.layer_out = nn.Linear(64, num_class) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.layer_2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3EtRkKEHH2"
      },
      "source": [
        "class my_downstream:\n",
        "    def __init__(self, train_x, train_y, test_x = None, test_y = None, valid_x = None, valid_y = None, ENABLE_LOGS = 1):\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.test_x = test_x\n",
        "        self.test_y = test_y\n",
        "        self.valid_x = valid_x\n",
        "        self.valid_y = valid_y\n",
        "        self.predict_x = None\n",
        "        self.predict_y = None\n",
        "\n",
        "        self.model = None\n",
        "        self.best_model = None\n",
        "        self.best_iter = None\n",
        "\n",
        "        self.ENABLE_LOGS = ENABLE_LOGS\n",
        "\n",
        "\n",
        "        self.accuracy_stats = {\n",
        "                                  'train': [],\n",
        "                                  \"val\": []\n",
        "                              }\n",
        "        self.loss_stats = {\n",
        "                              'train': [],\n",
        "                              \"val\": []\n",
        "                          }\n",
        "\n",
        "    def print_log(self, *arg, log_type=\"Info\"):\n",
        "        if(self.ENABLE_LOGS==1 or log_type!=\"Info\"): \n",
        "            print(\"[\"+log_type+\"]\",\" \".join(str(x) for x in arg))\n",
        "\n",
        "    def train_logistic(self, n_iter=500, random_state=0):\n",
        "        self.model = LogisticRegression(random_state=random_state,max_iter=n_iter)\n",
        "        self.print_log(\"Train\", self.model.__class__.__name__)\n",
        "        self.print_log(\"iteration:\",n_iter)\n",
        "        self.print_log(\"random_state:\",random_state)\n",
        "        self.model.fit(self.train_x, self.train_y)\n",
        "        self.print_log(\"Train Logistic Regression\", log_type=\"Success\")\n",
        "\n",
        "    def train_multiclass_nn(self, D_in, n_classes, EPOCHS=500, learning_rate = 1e-5, batch_size = 32, CONT = 0):\n",
        "        class_count = [i for i in get_class_distribution(self.train_y).values()]\n",
        "        class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
        "        # print(class_weights)\n",
        "        \n",
        "        \n",
        "        self.model = MulticlassClassification(num_feature = D_in, num_class=n_classes).to(DEVICE_AVAILABLE)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE_AVAILABLE))\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        # print(self.model)\n",
        "\n",
        "        # Convert to Tensor\n",
        "        input_x = torch.tensor(self.train_x).float()\n",
        "        input_y = torch.tensor(self.train_y).long()\n",
        "        valid_x = torch.tensor(self.valid_x).float()\n",
        "        valid_y = torch.tensor(self.valid_y).long()\n",
        "\n",
        "        # Create the DataLoader for our training set.\n",
        "        input_data = TensorDataset(input_x, input_y)\n",
        "        input_sampler = SequentialSampler(input_data)\n",
        "        input_dataloader = DataLoader(input_data, sampler=input_sampler, batch_size=batch_size)\n",
        "        self.print_log(\"Data size:\",str(len(self.train_x)), \"( Total batch\", str(len(input_dataloader)),'* size',str(batch_size),\")\")\n",
        "        valid_data = TensorDataset(valid_x, valid_y)\n",
        "        valid_sampler = SequentialSampler(valid_data)\n",
        "        valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)\n",
        "        self.print_log(\"Data size:\",str(len(self.valid_x)), \"( Total batch\", str(len(valid_dataloader)),'* size',str(batch_size),\")\")\n",
        "\n",
        "        min_loss = 999999\n",
        "\n",
        "        self.print_log(\"Begin training.\")\n",
        "        for e in tqdm(range(1, EPOCHS+1)):\n",
        "            # TRAINING\n",
        "            train_epoch_loss = 0\n",
        "            train_epoch_acc = 0\n",
        "\n",
        "            self.model.train()\n",
        "            for X_train_batch, y_train_batch in input_dataloader:\n",
        "                X_train_batch, y_train_batch = X_train_batch.to(DEVICE_AVAILABLE), y_train_batch.to(DEVICE_AVAILABLE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                y_train_pred = self.model(X_train_batch)\n",
        "                train_loss = criterion(y_train_pred, y_train_batch.squeeze_())\n",
        "                train_acc = my_evaluator.multi_acc(y_train_pred, y_train_batch)\n",
        "                \n",
        "                train_loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                train_epoch_loss += train_loss.item()\n",
        "                train_epoch_acc += train_acc.item()\n",
        "\n",
        "            # VALIDATION    \n",
        "            with torch.no_grad():\n",
        "        \n",
        "                val_epoch_loss = 0\n",
        "                val_epoch_acc = 0\n",
        "                \n",
        "                self.model.eval()\n",
        "                for X_val_batch, y_val_batch in valid_dataloader:\n",
        "                    X_val_batch, y_val_batch = X_val_batch.to(DEVICE_AVAILABLE), y_val_batch.to(DEVICE_AVAILABLE)\n",
        "                    \n",
        "                    y_val_pred = self.model(X_val_batch)\n",
        "                                \n",
        "                    val_loss = criterion(y_val_pred, y_val_batch.squeeze_())\n",
        "                    val_acc = my_evaluator.multi_acc(y_val_pred, y_val_batch)\n",
        "                    \n",
        "                    val_epoch_loss += val_loss.item()\n",
        "                    val_epoch_acc += val_acc.item()\n",
        "            self.loss_stats['train'].append(train_epoch_loss/len(input_dataloader))\n",
        "            self.loss_stats['val'].append(val_epoch_loss/len(valid_dataloader))\n",
        "            self.accuracy_stats['train'].append(train_epoch_acc/len(input_dataloader))\n",
        "            self.accuracy_stats['val'].append(val_epoch_acc/len(valid_dataloader))     \n",
        "    \n",
        "            if(min_loss > self.loss_stats['val'][-1]):\n",
        "                self.print_log(f'Epoch {e+0:03}: SAVE')\n",
        "                self.best_model = self.model\n",
        "                self.best_iter = e+1\n",
        "                min_loss = self.loss_stats['val'][-1]\n",
        "\n",
        "            # print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(input_dataloader):.5f} | Val Loss: {val_epoch_loss/len(valid_dataloader):.5f} | Train Acc: {train_epoch_acc/len(input_dataloader):.3f}| Val Acc: {val_epoch_acc/len(valid_dataloader):.3f}')\n",
        "\n",
        "    def train_linear_nn(self, D_in, n_classes, n_iter=500, learning_rate = 1e-5, batch_size = 32, CONT = 0):\n",
        "        list_train_loss = []\n",
        "        list_valid_loss = []\n",
        "      \n",
        "        # Convert to Tensor\n",
        "        input_x = torch.tensor(self.train_x).float()\n",
        "        input_y = torch.tensor(self.train_y).float()\n",
        "\n",
        "        # Create the DataLoader for our training set.\n",
        "        input_data = TensorDataset(input_x, input_y)\n",
        "        input_sampler = SequentialSampler(input_data)\n",
        "        input_dataloader = DataLoader(input_data, sampler=input_sampler, batch_size=batch_size)\n",
        "        self.print_log(\"Data size:\",str(len(self.train_x)), \"( Total batch\", str(len(input_dataloader)),'* size',str(batch_size),\")\")\n",
        "        \n",
        "        if(CONT == 0):\n",
        "            self.model = LinearLayer(D_in, n_classes).to(DEVICE_AVAILABLE)\n",
        "        self.print_log(\"Train\", self.model.__class__.__name__)\n",
        "        self.print_log(\"iteration:\",n_iter)\n",
        "\n",
        "        criterion = torch.nn.BCELoss()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        min_loss = 999999\n",
        "\n",
        "        digit_iter = len(str(n_iter))-1 # Report progress\n",
        "        for i in range(n_iter):\n",
        "            digit = len(str(len(input_dataloader)))-1 # Report progress\n",
        "            for step, batch in enumerate(input_dataloader):\n",
        "                \n",
        "                x_input = batch[0].to(DEVICE_AVAILABLE)\n",
        "                y_input = batch[1].to(DEVICE_AVAILABLE)\n",
        "                y_pred = self.model(x_input).squeeze()\n",
        "\n",
        "                loss = criterion(y_pred,y_input)\n",
        "\n",
        "                # if(step == 0 or (step+1)%(10**digit) == 0 or step == len(input_dataloader)-1): \n",
        "                #     self.print_log(\"Step:\",step+1,\"/\",len(input_dataloader),\":\",loss.item())\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step() \n",
        "\n",
        "            # Train\n",
        "            x_train = torch.tensor(self.train_x).float().to(DEVICE_AVAILABLE)\n",
        "            y_train = torch.tensor(self.train_y).float().to(DEVICE_AVAILABLE)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_vpred_train = self.model(x_train).squeeze()\n",
        "\n",
        "            iter_loss_train = criterion(y_vpred_train, y_train)\n",
        "            list_train_loss.append(iter_loss_train.item())\n",
        "\n",
        "            # Valid\n",
        "            x_valid = torch.tensor(self.valid_x).float().to(DEVICE_AVAILABLE)\n",
        "            y_valid = torch.tensor(self.valid_y).float().to(DEVICE_AVAILABLE)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_vpred_valid = self.model(x_valid).squeeze()\n",
        "\n",
        "            iter_loss_valid = criterion(y_vpred_valid, y_valid)\n",
        "            list_valid_loss.append(iter_loss_valid.item())\n",
        "\n",
        "            if(min_loss > iter_loss_valid.item()):\n",
        "                self.print_log(\"Iteration:\",i+1,\"/\",n_iter,\":\",'train',iter_loss_train.item(),'valid',iter_loss_valid.item())\n",
        "                self.best_model = self.model\n",
        "                self.best_iter = i+1\n",
        "                min_loss = iter_loss_valid.item()\n",
        "            # else:\n",
        "            #     break\n",
        "        \n",
        "        self.print_log(\"Train Linear NN\", log_type=\"Success\")   \n",
        "        return list_train_loss, list_valid_loss   \n",
        "\n",
        "    def get_model_name(self):\n",
        "        if(self.model is None):\n",
        "            return \"None\"\n",
        "        else:\n",
        "            return self.model.__class__.__name__\n",
        "\n",
        "    def predict(self, test_x = None):\n",
        "        # Train Data\n",
        "        self.predict_x = self.test_x if test_x is None else test_x\n",
        "        if(self.predict_x is None): return print_log(\"No test data\", log_type=\"Error\")\n",
        "\n",
        "        # Model\n",
        "        if(self.model is None): \n",
        "            print_log(\"Predict\",\"NULL MODEL\", log_type=\"WARNING\")\n",
        "            self.predict_y = [0]*len(self.predict_x)\n",
        "        elif(self.get_model_name() == 'LogisticRegression'):\n",
        "            print_log(\"Predict\",self.get_model_name())\n",
        "            self.predict_y = self.model.predict(self.predict_x)\n",
        "        elif(self.get_model_name() == 'LinearLayer'):\n",
        "            print_log(\"Predict\",self.get_model_name())\n",
        "            input = torch.tensor(self.predict_x).float().to(DEVICE_AVAILABLE)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                self.predict_y = self.best_model(input).squeeze().round().cpu().detach().numpy()\n",
        "        elif(self.get_model_name() == 'MulticlassClassification'):\n",
        "            print_log(\"Predict\",self.get_model_name())\n",
        "            # Convert to Tensor\n",
        "            input_x = torch.tensor(self.predict_x).float()\n",
        "            input_y = torch.tensor(self.test_y).long()\n",
        "\n",
        "            # Create the DataLoader for our training set.\n",
        "            input_data = TensorDataset(input_x, input_y)\n",
        "            input_sampler = SequentialSampler(input_data)\n",
        "            input_dataloader = DataLoader(input_data, sampler=input_sampler, batch_size=1)\n",
        "            self.print_log(\"Data size:\",str(len(self.train_x)), \"( Total batch\", str(len(input_dataloader)),'* size',str(1),\")\")\n",
        "\n",
        "            y_pred_list = []\n",
        "            with torch.no_grad():\n",
        "                self.best_model.eval()\n",
        "                for X_batch, _ in input_dataloader:\n",
        "                    X_batch = X_batch.to(DEVICE_AVAILABLE)\n",
        "                    y_test_pred = self.best_model(X_batch)\n",
        "                    _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n",
        "                    y_pred_list.append(y_pred_tags.cpu().numpy())\n",
        "            self.predict_y = [a.squeeze().tolist() for a in y_pred_list]\n",
        "        else:\n",
        "            print_log(\"Predict\",self.get_model_name())\n",
        "            print_log(\"something wrong with prediction function\", log_type=\"ERROR\")\n",
        "\n",
        "        return self.predict_x,self.predict_y\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.get_model_name()\n",
        "\n",
        "    def load_linear_nn(self, D_in, n_classes, model_path):\n",
        "        self.model = LinearLayer(D_in, n_classes).to(DEVICE_AVAILABLE)\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=DEVICE_AVAILABLE))\n",
        "        self.best_model = self.model\n",
        "\n",
        "    def load_multiclass_nn(self, D_in, n_classes, model_path):\n",
        "        self.model = MulticlassClassification(num_feature = D_in, num_class=n_classes).to(DEVICE_AVAILABLE)\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=DEVICE_AVAILABLE))\n",
        "        self.best_model = self.model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBWEY1V2SPnL"
      },
      "source": [
        "# labels = ['label_IM', 'label_ID', 'label_CE', 'label_RI', 'label_GS', 'label_GI', 'label_A', 'label_CD', 'label_PS', 'label_TPI']\n",
        "# learning_rate = 1e-5\n",
        "# batch_size = 32\n",
        "\n",
        "# print_log(\"Training Downstream Model\")\n",
        "# model = my_downstream(bert_train.get_features(),bert_train.get_labels(labels),\n",
        "#                           bert_test.get_features(),bert_test.get_labels(labels),\n",
        "#                           bert_valid.get_features(),bert_valid.get_labels(labels))\n",
        "\n",
        "# train_loss, valid_loss = model.train_linear_nn(D_in = 768, \n",
        "#                           n_classes = 1 if type(labels) == str else len(labels), \n",
        "#                           n_iter=100, \n",
        "#                           learning_rate = learning_rate, \n",
        "#                           batch_size = batch_size)\n",
        "  \n",
        "# _,predict_y = model.predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFERO4Jo9n1H"
      },
      "source": [
        "### Class: my_evaluator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Txmvj0zU7K"
      },
      "source": [
        "class my_evaluator:\n",
        "    LABELS_HOC_FULL = ['activating invasion and metastasis', 'avoiding immune destruction',\n",
        "                  'cellular energetics', 'enabling replicative immortality', 'evading growth suppressors',\n",
        "                  'genomic instability and mutation', 'inducing angiogenesis', 'resisting cell death',\n",
        "                  'sustaining proliferative signaling', 'tumor promoting inflammation']\n",
        "    LABELS_HOC_SHORT = ['label_IM', 'label_ID', \n",
        "                       'label_CE', 'label_RI', 'label_GS', \n",
        "                       'label_GI', 'label_A', 'label_CD', \n",
        "                       'label_PS', 'label_TPI']\n",
        "    @classmethod\n",
        "    def divide(self, x, y):\n",
        "        return np.true_divide(x, y, out=np.zeros_like(x, dtype=np.float), where=y != 0)\n",
        "\n",
        "    @classmethod\n",
        "    def get_p_r_f_arrary(self, test_predict_label, test_true_label):\n",
        "        num, cat = test_predict_label.shape\n",
        "        # print(num,cat)\n",
        "        acc_list = []\n",
        "        prc_list = []\n",
        "        rec_list = []\n",
        "        f_score_list = []\n",
        "        for i in range(num):\n",
        "            # print(test_predict_label[i])\n",
        "            # print(test_true_label[i])\n",
        "\n",
        "            acc = accuracy_score(test_true_label[i], test_predict_label[i])\n",
        "            prc,rec,f_score,_ = precision_recall_fscore_support(test_true_label[i], test_predict_label[i], average='macro')\n",
        "\n",
        "            if prc == 0 and rec == 0:\n",
        "                f_score = 0\n",
        "            else:\n",
        "                f_score = 2 * prc * rec / (prc + rec)\n",
        "\n",
        "            acc_list.append(acc)\n",
        "            prc_list.append(prc)\n",
        "            rec_list.append(rec)\n",
        "            f_score_list.append(f_score)\n",
        "\n",
        "        # print(prc_list)\n",
        "        # print(rec_list)\n",
        "\n",
        "        mean_prc = np.mean(prc_list)\n",
        "        mean_rec = np.mean(rec_list)\n",
        "        f_score = self.divide(2 * mean_prc * mean_rec, (mean_prc + mean_rec))\n",
        "        return mean_prc, mean_rec, f_score\n",
        "\n",
        "    @classmethod\n",
        "    def hoc_sentence2doc(self, input_df):\n",
        "        # Output variables\n",
        "        data = {}\n",
        "        input_labels_count = dict(zip(self.LABELS_HOC_FULL, [0]*len(self.LABELS_HOC_FULL))) # sentence\n",
        "\n",
        "        # Group sentence back into documents      \n",
        "        for i in range(len(input_df)):\n",
        "            input_row = input_df.iloc[i]\n",
        "            \n",
        "            key = input_row['index'][:input_row['index'].find('_')]\n",
        "\n",
        "            if key not in data:\n",
        "                data[key] = set()\n",
        "\n",
        "            if not pd.isna(input_row['labels']):\n",
        "                for l in input_row['labels'].split(','):\n",
        "                    ind,val = l.split('_')\n",
        "                    if(val != '0'):\n",
        "                        data[key].add(self.LABELS_HOC_FULL[int(ind)])\n",
        "                        input_labels_count[self.LABELS_HOC_FULL[int(ind)]] += 1\n",
        "\n",
        "        return data, input_labels_count\n",
        "\n",
        "    @classmethod\n",
        "    def hoc_labels2np(self, data):\n",
        "        labels_list = dict(zip(self.LABELS_HOC_FULL, [[],[],[],[],[],[],[],[],[],[]]))\n",
        "\n",
        "        y_np = []\n",
        "\n",
        "        for k, v in data.items():\n",
        "            # print(k)\n",
        "            # print(true,pred)\n",
        "            t = [0] * len(self.LABELS_HOC_FULL)\n",
        "            for i in v:\n",
        "                t[self.LABELS_HOC_FULL.index(i)] = 1\n",
        "\n",
        "            y_np.append(t)\n",
        "\n",
        "            for lab in self.LABELS_HOC_FULL:\n",
        "                if(lab in v):\n",
        "                    labels_list[lab].append(1)\n",
        "                else:\n",
        "                    labels_list[lab].append(0)\n",
        "\n",
        "        return np.array(y_np),labels_list\n",
        "\n",
        "    @classmethod\n",
        "    def analysis_hoc(self, input_df):\n",
        "        # Reformat to Paper evaluator format\n",
        "        input_df = input_df[['filename_line','label']].copy()\n",
        "        input_df.columns = ['index','labels']\n",
        "\n",
        "        data, labels_counts_sen = self.hoc_sentence2doc(input_df)\n",
        "\n",
        "        print_log('HoC Dataset Details')\n",
        "        print_log('No. of Documents:',len(data))\n",
        "        print_log('No. of Sentences:',len(input_df))\n",
        "        # print(labels_counts_sen)\n",
        "\n",
        "        y_np, labels_counts_doc = self.hoc_labels2np(data)\n",
        "        # print(y_np)\n",
        "        # print(labels_counts_doc)\n",
        "        res = pd.DataFrame()\n",
        "        for lab in self.LABELS_HOC_FULL:\n",
        "            print_log(lab,sum(labels_counts_doc[lab]),len(labels_counts_doc[lab]))\n",
        "            temp_df = pd.DataFrame([[sum(labels_counts_doc[lab]),len(labels_counts_doc[lab])]], columns=['sum','len'], index=[lab])\n",
        "            res = res.append(temp_df)\n",
        "\n",
        "        return res\n",
        "\n",
        "    @classmethod\n",
        "    def eval_hoc(self, input_df):   \n",
        "        print_log(\"eval hoc\",log_type=\"Function\")\n",
        "    \n",
        "        # Reformat to Paper evaluator format\n",
        "        ## Label need to be in a format of list of 10 cancers in fixed order\n",
        "        true_df = input_df[['filename_line','label']].copy()\n",
        "        pred_df = input_df[['filename_line','prediction']].copy()\n",
        "        true_df.columns = ['index','labels']\n",
        "        pred_df.columns = ['index','labels']\n",
        "\n",
        "        # Group sentence back into documents \n",
        "        data_true, true_labels_count_sen = self.hoc_sentence2doc(true_df)\n",
        "        data_pred, pred_labels_count_sen = self.hoc_sentence2doc(pred_df)\n",
        "\n",
        "        # merge data_true/pred into format of {'key':(set(true),set(pred))}\n",
        "        assert data_true.keys() == data_pred.keys(), 'Key mismatch'\n",
        "        all_keys = set(data_true.keys()).union(data_pred.keys()) \n",
        "\n",
        "        data = {}\n",
        "        for k in all_keys:\n",
        "            data[k] = (data_true[k],data_pred[k]) \n",
        "        # print(data)\n",
        "        assert len(data) == 371, 'There are 371 documents in the test set: %d' % len(data)\n",
        "        \n",
        "        print_log('HoC Dataset Details')\n",
        "        print_log('No. of Documents:',len(data))\n",
        "        print_log('No. of Sentences:',len(true_df),'/',len(pred_df))\n",
        "        print(true_labels_count_sen,pred_labels_count_sen)\n",
        "\n",
        "        # Write into dataframe\n",
        "        res_count_sen = pd.DataFrame()\n",
        "        for lab in self.LABELS_HOC_FULL:\n",
        "            temp_df = pd.DataFrame([[true_labels_count_sen[lab],pred_labels_count_sen[lab],len(true_df)]], columns=['sentence_count_label','sentence_count_pred','sentence_count_total'], index=[lab])\n",
        "            res_count_sen = res_count_sen.append(temp_df)\n",
        "        # print(res_count)\n",
        "\n",
        "        y_test, true_labels_count_doc = self.hoc_labels2np(data_true)\n",
        "        y_pred, pred_labels_count_doc = self.hoc_labels2np(data_pred)\n",
        "        \n",
        "        res_count_doc = pd.DataFrame()\n",
        "        for lab in self.LABELS_HOC_FULL:\n",
        "            temp_df = pd.DataFrame([[sum(true_labels_count_doc[lab]),sum(pred_labels_count_doc[lab]),len(true_labels_count_doc[lab])]], columns=['doc_count_label','doc_count_pred','doc_count_total'], index=[lab])\n",
        "            res_count_doc = res_count_doc.append(temp_df)\n",
        "        res_confmat = pd.DataFrame(columns=['tn','fp','fn','tp'])\n",
        "\n",
        "        # print(true_labels_list,pred_labels_list)\n",
        "        for lab in self.LABELS_HOC_FULL:\n",
        "            # print(lab)\n",
        "            df2 = pd.DataFrame([list(confusion_matrix(true_labels_count_doc[lab],pred_labels_count_doc[lab]).ravel())], columns=['tn','fp','fn','tp'], index=[lab])\n",
        "            res_confmat = res_confmat.append(df2)\n",
        "        # print(res_confmat)\n",
        "        df_res = pd.concat([res_confmat,res_count_sen,res_count_doc], axis=1)\n",
        "        print(df_res)\n",
        "\n",
        "        r, p, f1 = self.get_p_r_f_arrary(y_pred, y_test)\n",
        "        print('Precision: {:.6f}'.format(p))\n",
        "        print('Recall   : {:.6f}'.format(r))\n",
        "        print('F1       : {:.6f}'.format(f1))\n",
        "        return float(r), float(p), float(f1) , df_res\n",
        "\n",
        "    @classmethod\n",
        "    def multi_acc(self, y_pred, y_test):\n",
        "        y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "        \n",
        "        correct_pred = (y_pred_tags == y_test).float()\n",
        "        acc = correct_pred.sum() / len(correct_pred)\n",
        "        \n",
        "        acc = torch.round(acc * 100)\n",
        "        \n",
        "        return acc\n",
        "\n",
        "    @classmethod\n",
        "    def eval_pubmedqa(self, input_df):\n",
        "        class2idx = {\n",
        "                'no':0,\n",
        "                'maybe':1,\n",
        "                'yes':2\n",
        "        }\n",
        "        idx2class = {v: k for k, v in class2idx.items()}\n",
        "        input_df['label'].replace(idx2class, inplace=True)\n",
        "        input_df['prediction'].replace(idx2class, inplace=True)\n",
        "\n",
        "        confusion_matrix_df = pd.DataFrame(confusion_matrix(input_df.label.values, input_df.prediction.values))\n",
        "        class_report = classification_report(input_df.label.values, input_df.prediction.values, digits=4,output_dict = True)\n",
        "        print(class_report)\n",
        "        # sns.heatmap(confusion_matrix_df, annot=True)\n",
        "        return class_report , confusion_matrix_df\n",
        "\n",
        "    @classmethod\n",
        "    def eval_bioasq(self, input_df):\n",
        "        class2idx = {\n",
        "                'no':0,\n",
        "                'yes':1\n",
        "        }\n",
        "        idx2class = {v: k for k, v in class2idx.items()}\n",
        "        input_df['label'].replace(idx2class, inplace=True)\n",
        "        input_df['prediction'].replace(idx2class, inplace=True)\n",
        "\n",
        "        confusion_matrix_df = pd.DataFrame(confusion_matrix(input_df.label.values, input_df.prediction.values))\n",
        "        class_report = classification_report(input_df.label.values, input_df.prediction.values, digits = 4,output_dict = True)\n",
        "        print(class_report)\n",
        "        sns.heatmap(confusion_matrix_df, annot=True)\n",
        "\n",
        "\n",
        "        acc = accuracy_score(input_df.label.values, input_df.prediction.values)\n",
        "        prc,rec,f_score,_ = precision_recall_fscore_support(input_df.label.values, input_df.prediction.values, average='macro')\n",
        "\n",
        "        print(\"acc\",acc)\n",
        "        print(\"prc\",prc)\n",
        "        print(\"rec\",rec)\n",
        "        print(\"f_score\",f_score)\n",
        "\n",
        "        return class_report , confusion_matrix_df\n",
        "\n",
        "# eval_hoc(temp_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXbxr48NdtTK"
      },
      "source": [
        "# temp_df = bert_test.df_BERT.copy()\n",
        "# temp_df['prediction'] = pd.Series(map(lambda x: [str(i)+\"_\"+str(int(x[i])) for i in range(len(x))], predict_y))\n",
        "# temp_df['prediction'] = temp_df['prediction'].apply(lambda x: ','.join(x))\n",
        "# r, p, f1 = my_evaluator.eval_hoc(temp_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQx5qdSyhea_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUGQ4ZDF39T"
      },
      "source": [
        "## Model Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9hHGU9xIZNG"
      },
      "source": [
        "### Fine-tuned Hall-of-Cancer (HoC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PkI0Km4GbGp"
      },
      "source": [
        "#### Assisting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzFKQqJTuPcZ"
      },
      "source": [
        "def text_dependent(df_input, shift_level=0):\n",
        "    temp_df = df_input.copy()\n",
        "    new = temp_df['filename_line'].str.split(\"_\", n = 1, expand = True)\n",
        "    # making separate first name column from new data frame\n",
        "    temp_df[\"filename\"]= new[0]\n",
        "    # making separate last name column from new data frame\n",
        "    temp_df[\"sentence\"]= new[1]\n",
        "    if(shift_level==1):\n",
        "        df_input['text'] = temp_df.groupby('filename').text.apply(lambda x: x.shift(1).fillna('')+' '+ x).str.strip()\n",
        "    elif(shift_level==2):\n",
        "        df_input['text'] = temp_df.groupby('filename').text.apply(lambda x: x.shift(2).fillna('')+' '+ x.shift(1).fillna('')+' '+ x).str.strip()\n",
        "    elif(shift_level==3):\n",
        "        df_input['text'] = temp_df.groupby('filename').text.apply(lambda x: x.shift(3).fillna('')+' '+ x.shift(2).fillna('')+' '+ x.shift(1).fillna('')+' '+ x).str.strip()\n",
        "    return df_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7ovR6tFuNBc"
      },
      "source": [
        "def transform_dataset(DATAPATH,DATASET,PRETRAIN_MODEL='bert-base-uncased',TOKEN_SIZE=128, SHIFT_LEVEL=None, FORCE=False):\n",
        "    print_log(\"Try loading data from cache\")\n",
        "    temp_path = os.path.join(DATAPATH,\"datasets\",\"transformed\",DATASET,PRETRAIN_MODEL)\n",
        "    if(SHIFT_LEVEL == None or SHIFT_LEVEL == 0):\n",
        "        temp_path = os.path.join(temp_path,\"token_length_\"+str(TOKEN_SIZE))\n",
        "    else:\n",
        "        temp_path = os.path.join(temp_path,\"token_length_\"+str(TOKEN_SIZE)+\"_shift_\"+str(SHIFT_LEVEL))\n",
        "\n",
        "    temppath_train = os.path.join(temp_path,\"train.csv\")\n",
        "    temppath_valid = os.path.join(temp_path,\"valid.csv\")\n",
        "    temppath_test = os.path.join(temp_path,\"test.csv\")\n",
        "    \n",
        "    print_log(\"Train file exist:\",os.path.isfile(temppath_train),\"(\",temppath_train,\")\")\n",
        "    print_log(\"Valid file exist:\",os.path.isfile(temppath_valid),\"(\",temppath_valid,\")\")\n",
        "    print_log(\"Test file exist:\",os.path.isfile(temppath_test),\"(\",temppath_test,\")\")\n",
        "    \n",
        "    if((os.path.isfile(temppath_train) and os.path.isfile(temppath_valid) and os.path.isfile(temppath_valid)) and not FORCE):\n",
        "        df_train = pd.read_csv(temppath_train).iloc[:, 1:]\n",
        "        df_valid = pd.read_csv(temppath_valid).iloc[:, 1:]\n",
        "        df_test = pd.read_csv(temppath_test).iloc[:, 1:]\n",
        "        bert_train = my_BERT(df_train, is_transform=True)\n",
        "        bert_test = my_BERT(df_test, is_transform=True)\n",
        "        bert_valid = my_BERT(df_valid, is_transform=True)\n",
        "        print_log(\"Load Data From Existing\",log_type=\"Success\")\n",
        "        return bert_train, bert_test, bert_valid\n",
        "\n",
        "    print_log(\"Transform Data\",\"FORCE\" if FORCE else \"\")\n",
        "    temp_path = os.path.join(DATAPATH,\"datasets\",\"raw\",DATASET)\n",
        "    temppath_train = os.path.join(temp_path,\"train.tsv\")\n",
        "    temppath_valid = os.path.join(temp_path,\"dev.tsv\")\n",
        "    temppath_test = os.path.join(temp_path,\"test.tsv\")\n",
        "\n",
        "    df_train = pd.read_csv(temppath_train, sep='\\t')\n",
        "    df_test = pd.read_csv(temppath_test, sep='\\t')\n",
        "    df_valid = pd.read_csv(temppath_valid, sep='\\t')\n",
        "\n",
        "    # TO DO : Modify this if not HoC\n",
        "    df_train.columns = ['label','text','filename_line']\n",
        "    df_test.columns = ['label','text','filename_line']\n",
        "    df_valid.columns = ['label','text','filename_line']\n",
        "\n",
        "    if(SHIFT_LEVEL != None):\n",
        "        df_train = text_dependent(df_train,SHIFT_LEVEL)\n",
        "        df_test = text_dependent(df_test,SHIFT_LEVEL)\n",
        "        df_valid = text_dependent(df_valid,SHIFT_LEVEL)\n",
        "\n",
        "    bert_train = my_BERT(df_train)\n",
        "    bert_test = my_BERT(df_test)\n",
        "    bert_valid = my_BERT(df_valid)\n",
        "\n",
        "    bert_train.load_pretrain_bert(PRETRAIN_MODEL)\n",
        "    bert_test.load_pretrain_bert(PRETRAIN_MODEL)\n",
        "    bert_valid.load_pretrain_bert(PRETRAIN_MODEL)\n",
        "\n",
        "    print_log(\"BERTTransform: Train Data\")\n",
        "    bert_train.bert_transform(DEVICE_AVAILABLE, token_length=TOKEN_SIZE)\n",
        "    print_log(\"BERTTransform: Test Data\")\n",
        "    bert_test.bert_transform(DEVICE_AVAILABLE, token_length=TOKEN_SIZE)\n",
        "    print_log(\"BERTTransform: Valid Data\")\n",
        "    bert_valid.bert_transform(DEVICE_AVAILABLE, token_length=TOKEN_SIZE)\n",
        "\n",
        "    if(SHIFT_LEVEL == None):\n",
        "        temp_path = os.path.join(DATAPATH,\"datasets\",\"transformed\",DATASET,PRETRAIN_MODEL,\"token_length_\"+str(TOKEN_SIZE))\n",
        "    else:\n",
        "        temp_path = os.path.join(DATAPATH,\"datasets\",\"transformed\",DATASET,PRETRAIN_MODEL,\"token_length_\"+str(TOKEN_SIZE)+\"_shift_\"+str(SHIFT_LEVEL))\n",
        "    Path(os.path.join(temp_path)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    temp_df = bert_train.get_features_df(['filename_line','label'])\n",
        "    temp_df.to_csv(os.path.join(temp_path,\"train.csv\"))\n",
        "    print_log(len(df_train),\"/\",len(temp_df))\n",
        "    temp_df = bert_test.get_features_df(['filename_line','label'])\n",
        "    temp_df.to_csv(os.path.join(temp_path,\"test.csv\"))\n",
        "    print_log(len(df_test),\"/\",len(temp_df))\n",
        "    temp_df = bert_valid.get_features_df(['filename_line','label'])\n",
        "    temp_df.to_csv(os.path.join(temp_path,\"valid.csv\"))\n",
        "    print_log(len(df_valid),\"/\",len(temp_df))\n",
        "\n",
        "    return bert_train, bert_test, bert_valid\n",
        "\n",
        "# transform_dataset(DATAPATH = \"/content/drive/MyDrive/MinorThesis/\",\n",
        "#     DATASET = \"HoC\",\n",
        "#     TOKEN_SIZE = 128,\n",
        "#     PRETRAIN_MODEL = 'biobert-base-uncased',\n",
        "#     SHIFT_LEVEL = None,\n",
        "#     FORCE = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2V6rgEeGtrI"
      },
      "source": [
        "def train_linear_model(BERT_TRAIN, BERT_TEST, BERT_VALID, LABELS=['label'], LEARNING_RATE = 1e-5, BATCH_SIZE = 32, N_ITER=3000):\n",
        "    print_log(\"learning_rate:\",LEARNING_RATE)\n",
        "    print_log(\"batch_size\",BATCH_SIZE)\n",
        "    print_log(\"N_ITER\",N_ITER)\n",
        "    print_log(\"Training Downstream Model\")\n",
        "\n",
        "    model = my_downstream(BERT_TRAIN.get_features(),BERT_TRAIN.get_labels(LABELS),\n",
        "                          BERT_TEST.get_features(),BERT_TEST.get_labels(LABELS),\n",
        "                          BERT_VALID.get_features(),BERT_VALID.get_labels(LABELS))\n",
        "    train_loss, valid_loss = model.train_linear_nn(D_in = 768, \n",
        "                          n_classes = 1 if type(LABELS) == str else len(LABELS), \n",
        "                          n_iter=N_ITER, \n",
        "                          learning_rate = LEARNING_RATE, \n",
        "                          batch_size = BATCH_SIZE)\n",
        "    return model, train_loss, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcn8Rwb1Gm41"
      },
      "source": [
        "#### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya6_62lRS_QW"
      },
      "source": [
        "# HoC\n",
        "def run_dsgenerator(DATAPATH, DATASET, LABELS=['label'], PRETRAIN_MODEL = 'bert-base-uncased', TOKEN_SIZE = 128, SHIFT_LEVEL = None , LEARNING_RATE = 1e-5, BATCH_SIZE = 32, N_ITER=3000):\n",
        "    print_log(\"Run Generator\",\"Function\")\n",
        "    \n",
        "    # UNIQUE IDENTIFIER USING\n",
        "    sttime = datetime.now().strftime('%Y%m%d_%H-%M-%S')\n",
        "\n",
        "    bert_train, bert_test, bert_valid = transform_dataset(DATAPATH = DATAPATH,\n",
        "                                                          DATASET = DATASET,\n",
        "                                                          PRETRAIN_MODEL = PRETRAIN_MODEL,\n",
        "                                                          SHIFT_LEVEL = SHIFT_LEVEL,\n",
        "                                                          TOKEN_SIZE = TOKEN_SIZE)\n",
        "\n",
        "    bert_train.extract_hoc_label()\n",
        "    bert_test.extract_hoc_label()\n",
        "    bert_valid.extract_hoc_label()\n",
        "\n",
        "    # TRAINING\n",
        "    model, train_loss, valid_loss = train_linear_model(bert_train, bert_test, bert_valid,\n",
        "                               LABELS, LEARNING_RATE, BATCH_SIZE, N_ITER)\n",
        "    # print_log(\"learning_rate:\",LEARNING_RATE)\n",
        "    # print_log(\"batch_size\",BATCH_SIZE)\n",
        "    # print_log(\"Training Downstream Model\")\n",
        "    # model = my_downstream(bert_train.get_features(),bert_train.get_labels(LABELS),\n",
        "    #                       bert_test.get_features(),bert_test.get_labels(LABELS),\n",
        "    #                       bert_valid.get_features(),bert_valid.get_labels(LABELS))\n",
        "    # train_loss, valid_loss = model.train_linear_nn(D_in = 768, \n",
        "    #                       n_classes = 1 if type(LABELS) == str else len(LABELS), \n",
        "    #                       n_iter=N_ITER, \n",
        "    #                       learning_rate = LEARNING_RATE, \n",
        "    #                       batch_size = BATCH_SIZE)\n",
        "  \n",
        "    _,predict_y = model.predict()\n",
        "\n",
        "    temp_df = bert_test.df_BERT.copy()\n",
        "    temp_df['prediction'] = pd.Series(map(lambda x: [str(i)+\"_\"+str(int(x[i])) for i in range(len(x))], predict_y))\n",
        "    temp_df['prediction'] = temp_df['prediction'].apply(lambda x: ','.join(x))\n",
        "    r, p, f1, _ = my_evaluator.eval_hoc(temp_df)\n",
        "\n",
        "    result = {}\n",
        "    result['dataset'] = DATASET\n",
        "    result['labels'] = LABELS\n",
        "    \n",
        "    result['pretrain_model'] = PRETRAIN_MODEL + '-tks' + str(TOKEN_SIZE)\n",
        "    result['downstream_model'] = model.get_model_name()\n",
        "    result['downstream_model_savepoint'] = \"model_\"+sttime+\".pt\"\n",
        "    \n",
        "    result['recall'] = r\n",
        "    result['precision'] = p\n",
        "    result['f1score'] = f1\n",
        "\n",
        "    result['best_iter'] = model.best_iter\n",
        "    \n",
        "    result['SHIFT_LEVEL'] = SHIFT_LEVEL\n",
        "    result['LEARNING_RATE'] = LEARNING_RATE\n",
        "    result['BATCH_SIZE'] = BATCH_SIZE\n",
        "    \n",
        "    # result['hyper_param'] = hp \n",
        "    # result['predict_y'] = predict_y\n",
        "\n",
        "    # SAVING SECTION\n",
        "    temp_path_model = os.path.join(DATAPATH,\"models\",DATASET,PRETRAIN_MODEL)\n",
        "    temp_path_result = os.path.join(DATAPATH,\"results\",DATASET,PRETRAIN_MODEL)\n",
        "\n",
        "    Path(temp_path_model).mkdir(parents=True, exist_ok=True)\n",
        "    Path(temp_path_result).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # SAVE MODEL\n",
        "    torch.save(model.best_model.state_dict(), os.path.join(temp_path_model,\"model_\"+sttime+\".pt\"))\n",
        "\n",
        "    res_df = pd.DataFrame(result.items(), columns=['key', 'result']).set_index('key')\n",
        "    res_df.to_json(os.path.join(temp_path_result,\"result_\"+sttime+\".json\"))\n",
        "\n",
        "    # SAVE PLOT\n",
        "    plt.plot(train_loss, label=\"train\")\n",
        "    plt.plot(valid_loss, label=\"valid\")\n",
        "    plt.title(PRETRAIN_MODEL+\"-\"+DATASET+\"-\"+str(TOKEN_SIZE))\n",
        "    plt.suptitle(str(BATCH_SIZE)+\"-\"+str(LEARNING_RATE))\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(temp_path_result,\"result_\"+sttime+\".png\"))\n",
        "\n",
        "    print_log(\"\",log_type=\"----------\")\n",
        "    # return predict_y\n",
        "    return result\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCybSZTqhw9_"
      },
      "source": [
        "# list_cancer = ['label_IM', 'label_ID', 'label_CE', 'label_RI', 'label_GS', 'label_GI', 'label_A', 'label_CD', 'label_PS', 'label_TPI']\n",
        "    \n",
        "# TARGET_LABEL = list_cancer\n",
        "# TARGET_DATASET = \"HoC\" # \"dat_hoc\",\"dat_semi\"\n",
        "# TARGET_PATH = '/content/drive/MyDrive/MinorThesis/'\n",
        "# PRETRAIN_MODEL = 'bert-base-uncased'\n",
        "# N_ITER=1000\n",
        "\n",
        "# BATCH_SIZE = 16\n",
        "# LEARNING_RATE = 5e-5\n",
        "# SHIFT_LEVEL=None\n",
        "\n",
        "# # for i in range(10):\n",
        "# res = run_dsgenerator(TARGET_PATH,TARGET_DATASET,TARGET_LABEL,\n",
        "#                             TOKEN_SIZE=512, PRETRAIN_MODEL=PRETRAIN_MODEL, \n",
        "#                             LEARNING_RATE = LEARNING_RATE, BATCH_SIZE = BATCH_SIZE,\n",
        "#                             N_ITER = N_ITER, SHIFT_LEVEL=SHIFT_LEVEL)\n",
        "# res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWSI3kvaaChq"
      },
      "source": [
        "# # # For test in Colab Only\n",
        "# DATAPATH = \"/content/drive/MyDrive/MinorThesis/\"\n",
        "# DATASET = \"HoC\"\n",
        "# TOKEN_SIZE = 128\n",
        "# PRETRAIN_MODEL = 'bert-base-uncased'\n",
        "# SHIFT_LEVEL = None\n",
        "# IS_TRANSFORM = True\n",
        "\n",
        "# temp_path = os.path.join(DATAPATH,\"datasets\",\"transformed\",DATASET,PRETRAIN_MODEL);\n",
        "# if(SHIFT_LEVEL == None):\n",
        "#     temp_path = os.path.join(temp_path,\"token_length_\"+str(TOKEN_SIZE))\n",
        "# else:\n",
        "#     temp_path = os.path.join(temp_path,\"token_length_\"+str(TOKEN_SIZE)+\"_shift_\"+str(SHIFT_LEVEL))\n",
        "\n",
        "# temppath_train = os.path.join(temp_path,\"train.csv\")\n",
        "# temppath_valid = os.path.join(temp_path,\"valid.csv\")\n",
        "# temppath_test = os.path.join(temp_path,\"test.csv\")\n",
        "\n",
        "# print_log(\"Train file exist:\",os.path.isfile(temppath_train),\"(\",temppath_train,\")\")\n",
        "# print_log(\"Valid file exist:\",os.path.isfile(temppath_valid),\"(\",temppath_valid,\")\")\n",
        "# print_log(\"Test file exist:\",os.path.isfile(temppath_test),\"(\",temppath_test,\")\")\n",
        "\n",
        "# df_train = pd.read_csv(temppath_train).iloc[:, 1:]\n",
        "# df_valid = pd.read_csv(temppath_valid).iloc[:, 1:]\n",
        "# df_test = pd.read_csv(temppath_test).iloc[:, 1:]\n",
        "\n",
        "# bert_train = my_BERT(extract_hoc_label(df_train),is_transform=IS_TRANSFORM)\n",
        "# bert_valid = my_BERT(extract_hoc_label(df_valid),is_transform=IS_TRANSFORM)\n",
        "# bert_test = my_BERT(extract_hoc_label(df_test),is_transform=IS_TRANSFORM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEQ3tdiOi_78"
      },
      "source": [
        "# BATCH_SIZE = 32\n",
        "# LEARNING_RATE = 5e-5\n",
        "# SHIFT_LEVEL=3\n",
        "\n",
        "# res = run_dsgenerator(TARGET_PATH,TARGET_DATASET,TARGET_LABEL,\n",
        "#                     TOKEN_SIZE=512, PRETRAIN_MODEL=PRETRAIN_MODEL, \n",
        "#                     LEARNING_RATE = LEARNING_RATE, BATCH_SIZE = BATCH_SIZE,\n",
        "#                     N_ITER = N_ITER, SHIFT_LEVEL=SHIFT_LEVEL)\n",
        "# res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK9UmEHQqbBP"
      },
      "source": [
        "### Fine-tuned PubMedQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZLHbUmvJqfC"
      },
      "source": [
        "#### Assisting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyX1U3XzEzDL"
      },
      "source": [
        "# Extract Fold ID (test,train)\n",
        "\n",
        "def get_pubmedqa_fold_id(DATAPATH,DATASET):\n",
        "    list_data_fold = []\n",
        "    for i in range(10):\n",
        "        temppath_train = os.path.join(DATAPATH,\"datasets\",\"raw\",DATASET,\"pqal_fold\"+str(i),\"train_set.json\")\n",
        "        temppath_valid = os.path.join(DATAPATH,\"datasets\",\"raw\",DATASET,\"pqal_fold\"+str(i),\"dev_set.json\")\n",
        "        \n",
        "        df_temp_train = pd.read_json(temppath_train).transpose().reset_index()\n",
        "        df_temp_valid = pd.read_json(temppath_valid).transpose().reset_index()\n",
        "\n",
        "        list_data_fold.append((df_temp_train['index'].values,df_temp_valid['index'].values))\n",
        "        # list_data_fold.append((df_temp_train,df_temp_valid))\n",
        "        # print(df_temp_train.shape,df_temp_valid.shape)\n",
        "    return list_data_fold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09FXETntmolH"
      },
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"rating_no\": 0,\n",
        "        \"rating_maybe\": 0,\n",
        "        \"rating_yes\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 0: \n",
        "            count_dict['rating_no'] += 1\n",
        "        elif i == 1: \n",
        "            count_dict['rating_maybe'] += 1\n",
        "        elif i == 2: \n",
        "            count_dict['rating_yes'] += 1             \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwyss6fQFNq4"
      },
      "source": [
        "def pubmedqa_train_linear_model(BERT_TRAIN, BERT_TEST, FOLDS_IDX, FOLD_I=0, LABELS=['label'], LEARNING_RATE = 1e-5, BATCH_SIZE = 32, N_ITER=3000):\n",
        "    print_log(\"learning_rate:\",LEARNING_RATE)\n",
        "    print_log(\"batch_size\",BATCH_SIZE)\n",
        "    print_log(\"N_ITER\",N_ITER)\n",
        "    print_log(\"Training Downstream Model\")\n",
        "\n",
        "    df_temp = BERT_TRAIN.df_BERT.copy()\n",
        "    df_train = df_temp[df_temp.id.isin(FOLDS_IDX[FOLD_I][0])]\n",
        "    df_valid = df_temp[df_temp.id.isin(FOLDS_IDX[FOLD_I][1])]\n",
        "\n",
        "    bert_train = my_BERT(df_train, is_transform=True)\n",
        "    bert_valid = my_BERT(df_valid, is_transform=True)\n",
        "\n",
        "    # print(np.array(df_train['label']))\n",
        "    # fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
        "    # # Train\n",
        "    # sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(np.array(df_train['label']))]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
        "    # # Validation\n",
        "    # sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(np.array(df_valid['label']))]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "    # # # Test\n",
        "    # # sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')\n",
        "\n",
        "    model = my_downstream(bert_train.get_features(),bert_train.get_labels(LABELS),\n",
        "                          BERT_TEST.get_features(),BERT_TEST.get_labels(LABELS),\n",
        "                          bert_valid.get_features(),bert_valid.get_labels(LABELS))\n",
        "    model.train_multiclass_nn(D_in = 768, \n",
        "                              n_classes = 3, \n",
        "                              EPOCHS=N_ITER, \n",
        "                              learning_rate = LEARNING_RATE, \n",
        "                              batch_size = BATCH_SIZE)\n",
        "\n",
        "    # Create dataframes\n",
        "    train_val_acc_df = pd.DataFrame.from_dict(model.accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "    train_val_loss_df = pd.DataFrame.from_dict(model.loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "    # Plot the dataframes\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
        "    sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
        "    sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYVP826uqQxz"
      },
      "source": [
        "def pubmedqa_transform_dataset(DATAPATH,DATASET,PRETRAIN_MODEL='bert-base-uncased',TOKEN_SIZE=128, SHIFT_LEVEL=None, FORCE=False, REASONING=False):\n",
        "    print_log(\"Try loading data from cache\")\n",
        "    temp_path = os.path.join(DATAPATH,\"datasets\",\"transformed\",DATASET,\"QuesAbs\", \"reasoning_required\" if REASONING else \"reasoning_free\", PRETRAIN_MODEL)\n",
        "    if(SHIFT_LEVEL == None):\n",
        "        temp_path = os.path.join(temp_path,\"token_length_\"+str(TOKEN_SIZE))\n",
        "    else:\n",
        "        temp_path = os.path.join(temp_path,\"token_length_\"+str(TOKEN_SIZE)+\"_shift_\"+str(SHIFT_LEVEL))\n",
        "\n",
        "    temppath_train = os.path.join(temp_path,\"train.csv\")\n",
        "    temppath_test = os.path.join(temp_path,\"test.csv\")\n",
        "    \n",
        "    print_log(\"Train file exist:\",os.path.isfile(temppath_train),\"(\",temppath_train,\")\")\n",
        "    print_log(\"Test file exist:\",os.path.isfile(temppath_test),\"(\",temppath_test,\")\")\n",
        "    \n",
        "    if((os.path.isfile(temppath_train) and os.path.isfile(temppath_test)) and not FORCE):\n",
        "        df_train = pd.read_csv(temppath_train).iloc[:, 1:]\n",
        "        df_test = pd.read_csv(temppath_test).iloc[:, 1:]\n",
        "        bert_train = my_BERT(df_train, is_transform=True)\n",
        "        bert_test = my_BERT(df_test, is_transform=True)\n",
        "        print_log(\"Load Data From Existing\",log_type=\"Success\")\n",
        "        return bert_train, bert_test\n",
        "\n",
        "    print_log(\"Transform Data\",\"FORCE\" if FORCE else \"\")\n",
        "    ### COPY FROM TRANSFOR DATASET FOR PUBMEDQA\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQl-ms9L9twJ"
      },
      "source": [
        "# Pubmedqa\n",
        "def run_pubmedqa_dsgenerator_allfold(DATAPATH, DATASET, LABELS=['label'], PRETRAIN_MODEL = 'bert-base-uncased', TOKEN_SIZE = 128, SHIFT_LEVEL = None , LEARNING_RATE = 1e-5, BATCH_SIZE = 32, N_ITER=3000, REASONING=False):\n",
        "    print_log(\"Run Generator\",\"Function\")\n",
        "    # UNIQUE IDENTIFIER USING\n",
        "    sttime = datetime.now().strftime('%Y%m%d_%H-%M-%S')\n",
        "    \n",
        "    \n",
        "\n",
        "    ####\n",
        "    print_log(\"PRETRAIN_MODEL: \",PRETRAIN_MODEL)  \n",
        "    print_log(\"REASONING: \",REASONING )\n",
        "    bert_train, bert_test = pubmedqa_transform_dataset(DATAPATH = DATAPATH,\n",
        "                                                          DATASET = DATASET,\n",
        "                                                          PRETRAIN_MODEL = PRETRAIN_MODEL,\n",
        "                                                          SHIFT_LEVEL = SHIFT_LEVEL,\n",
        "                                                          TOKEN_SIZE = TOKEN_SIZE,\n",
        "                                                       REASONING = REASONING)\n",
        "    \n",
        "    bert_train.class2idx_pubmedqa_label()\n",
        "    bert_test.class2idx_pubmedqa_label()\n",
        "\n",
        "    folds_idx = get_pubmedqa_fold_id(DATAPATH, DATASET)\n",
        "\n",
        "    list_acc = []\n",
        "    temp_df = bert_test.df_BERT.copy()\n",
        "\n",
        "    for i in range(10):\n",
        "        print_log(\"######## FOLD: \",i)\n",
        "        # TRAINING\n",
        "        model = pubmedqa_train_linear_model(bert_train, bert_test, folds_idx, i,\n",
        "                                  LABELS, LEARNING_RATE, BATCH_SIZE, N_ITER)\n",
        "        \n",
        "        # TEST\n",
        "        _,predict_y = model.predict()\n",
        "\n",
        "        temp_df['prediction'] = pd.Series(predict_y)\n",
        "        class_report, confusion_matrix_df = my_evaluator.eval_pubmedqa(temp_df)\n",
        "        temp_df.rename(columns={'prediction': 'reason_'+str(REASONING)+'_fold'+str(i)},inplace=True)\n",
        "        list_acc.append(class_report['accuracy'])\n",
        "\n",
        "        # SAVING SECTION\n",
        "        temp_path_model = os.path.join(DATAPATH,\"models\",DATASET,PRETRAIN_MODEL,'reason_'+str(REASONING),sttime)\n",
        "        Path(temp_path_model).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # SAVE MODEL\n",
        "        torch.save(model.best_model.state_dict(), os.path.join(temp_path_model,\"model_\"+\"fold_\"+str(i)+\".pt\"))\n",
        "\n",
        "    #### \n",
        "    print_log(\"PRETRAIN_MODEL: \",PRETRAIN_MODEL) \n",
        "    print_log(\"REASONING: \",not REASONING )\n",
        "    bert_train, bert_test = pubmedqa_transform_dataset(DATAPATH = DATAPATH,\n",
        "                                                          DATASET = DATASET,\n",
        "                                                          PRETRAIN_MODEL = PRETRAIN_MODEL,\n",
        "                                                          SHIFT_LEVEL = SHIFT_LEVEL,\n",
        "                                                          TOKEN_SIZE = TOKEN_SIZE,\n",
        "                                                       REASONING = not REASONING)\n",
        "    \n",
        "    # bert_train.class2idx_pubmedqa_label()\n",
        "    # bert_test.class2idx_pubmedqa_label()\n",
        "\n",
        "    # folds_idx = get_pubmedqa_fold_id(DATAPATH, DATASET)\n",
        "    # for i in range(10):\n",
        "    #     # TRAINING\n",
        "    #     print(i)\n",
        "    #     model = pubmedqa_train_linear_model(bert_train, bert_test, folds_idx, i,\n",
        "    #                               LABELS, LEARNING_RATE, BATCH_SIZE, N_ITER)\n",
        "    #     # TEST\n",
        "    #     _,predict_y = model.predict()\n",
        "\n",
        "    #     temp_df['prediction'] = pd.Series(predict_y)\n",
        "    #     class_report, confusion_matrix_df = my_evaluator.eval_pubmedqa(temp_df)\n",
        "    #     temp_df.rename(columns={'prediction': 'reason_'+str(not REASONING)+'_fold'+str(i)},inplace=True)\n",
        "    #     list_acc.append(class_report['accuracy'])\n",
        "\n",
        "    #     # SAVING SECTION\n",
        "    #     temp_path_model = os.path.join(DATAPATH,\"models\",DATASET,PRETRAIN_MODEL,'reason_'+str(not REASONING),sttime)\n",
        "    #     Path(temp_path_model).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    #     # SAVE MODEL\n",
        "    #     torch.save(model.best_model.state_dict(), os.path.join(temp_path_model,\"model_\"+\"fold_\"+str(i)+\".pt\"))\n",
        "\n",
        "    # #### MERGE\n",
        "    # print_log(\"REASONING MERGE\")\n",
        "    # temp_df['prediction'] = temp_df.apply(lambda x : x['reason_True'] if x['reason_True']==x['reason_False'] else \"maybe\", axis=1)\n",
        "    # class_report, confusion_matrix_df = my_evaluator.eval_pubmedqa(temp_df)\n",
        "\n",
        "    # result = {}\n",
        "    # result['dataset'] = DATASET\n",
        "    # result['labels'] = LABELS\n",
        "    \n",
        "    # result['pretrain_model'] = PRETRAIN_MODEL + '-tks' + str(TOKEN_SIZE)\n",
        "    # result['downstream_model'] = model.get_model_name()\n",
        "    # result['downstream_model_savepoint'] = \"model_\"+sttime+\".pt\"\n",
        "    \n",
        "    # result['summary'] = class_report\n",
        "    # # result['recall'] = r\n",
        "    # # result['precision'] = p\n",
        "    # # result['f1score'] = f1\n",
        "\n",
        "    # result['best_iter'] = model.best_iter\n",
        "    \n",
        "    # result['LEARNING_RATE'] = LEARNING_RATE\n",
        "    # result['BATCH_SIZE'] = BATCH_SIZE\n",
        "\n",
        "    # # SAVING SECTION\n",
        "    # temp_path_model = os.path.join(DATAPATH,\"models\",DATASET,\"reasoning_required\" if REASONING else \"reasoning_free\",PRETRAIN_MODEL)\n",
        "    # temp_path_result = os.path.join(DATAPATH,\"results\",DATASET,\"reasoning_required\" if REASONING else \"reasoning_free\",PRETRAIN_MODEL)\n",
        "\n",
        "    # Path(temp_path_model).mkdir(parents=True, exist_ok=True)\n",
        "    # Path(temp_path_result).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # # SAVE MODEL\n",
        "    # torch.save(model.best_model.state_dict(), os.path.join(temp_path_model,\"model_\"+sttime+\".pt\"))\n",
        "\n",
        "    # res_df = pd.DataFrame(result.items(), columns=['key', 'result']).set_index('key')\n",
        "    # res_df.to_json(os.path.join(temp_path_result,\"result_\"+sttime+\".json\"))\n",
        "\n",
        "    arr = np.array(list_acc)\n",
        "    arr2 = arr.reshape((1,10))\n",
        "    print_log(\"Results (REASONING_REQUIRED, REASONING_FREE):\",np.average(arr2, axis=1),log_type=\"SUCCESS\")\n",
        "\n",
        "    return list_acc\n",
        "\n",
        "TARGET_LABEL = ['label']\n",
        "TARGET_DATASET = \"pubmedqa\"\n",
        "TARGET_PATH = '/content/drive/MyDrive/MinorThesis/'\n",
        "PRETRAIN_MODEL = 'biobert-base-cased'\n",
        "N_ITER=300\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-5\n",
        "SHIFT_LEVEL=None\n",
        "\n",
        "# for bs in [16, 32]:\n",
        "#     for lr in [1e-5, 3e-3, 5e-5]:\n",
        "\n",
        "\n",
        "# for bert_model in ['biobert-base-cased']:\n",
        "#     for bs in [32]:\n",
        "#         for lr in [3e-3]:\n",
        "#             for i in range(45):\n",
        "#                 res = run_pubmedqa_dsgenerator_allfold(TARGET_PATH,TARGET_DATASET,TARGET_LABEL,\n",
        "#                                         TOKEN_SIZE=512, PRETRAIN_MODEL=bert_model, \n",
        "#                                         LEARNING_RATE = lr, BATCH_SIZE = bs,\n",
        "#                                         N_ITER = N_ITER, SHIFT_LEVEL=SHIFT_LEVEL,\n",
        "#                                         REASONING = True)\n",
        "# res\n",
        "\n",
        "\n",
        "# res = run_pubmedqa_dsgenerator_allfold(TARGET_PATH,TARGET_DATASET,TARGET_LABEL,\n",
        "#                         TOKEN_SIZE=512, PRETRAIN_MODEL=PRETRAIN_MODEL, \n",
        "#                         LEARNING_RATE = LEARNING_RATE, BATCH_SIZE = BATCH_SIZE,\n",
        "#                         N_ITER = N_ITER, SHIFT_LEVEL=SHIFT_LEVEL,\n",
        "#                         REASONING = True)\n",
        "# res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjil0Ay3VRFe"
      },
      "source": [
        "def run_pubmedqa_ensemble(DATAPATH, DATASET, MODEL_GROUP, LABELS=['label'], TOKEN_SIZE=128, SHIFT_LEVEL = None):\n",
        "    print_log(\"Run Ensemble\",\"Function\")\n",
        "\n",
        "    temp_path = os.path.join(DATAPATH,\"models\",DATASET,\"ensemble\",MODEL_GROUP)\n",
        "    LIST_PRETRAIN_MODEL = os.listdir(temp_path)\n",
        "    print_log(\"Ensemble pretrain model list:\",LIST_PRETRAIN_MODEL)\n",
        "\n",
        "    list_acc = []\n",
        "    list_results = []\n",
        "    list_results_f1 = []\n",
        "\n",
        "    all_pred_df = pd.DataFrame()\n",
        "\n",
        "    for pretrain_model in LIST_PRETRAIN_MODEL:\n",
        "        print_log(\"model:\",pretrain_model)\n",
        "\n",
        "        print_log(\"PRETRAIN_MODEL: \",pretrain_model)\n",
        "        REASONING = True  \n",
        "        print_log(\"REASONING: \",REASONING)\n",
        "        bert_train, bert_test = pubmedqa_transform_dataset(DATAPATH = DATAPATH,\n",
        "                                                           DATASET = DATASET,\n",
        "                                                           PRETRAIN_MODEL = pretrain_model,\n",
        "                                                           SHIFT_LEVEL = SHIFT_LEVEL,\n",
        "                                                           TOKEN_SIZE = TOKEN_SIZE,\n",
        "                                                           REASONING = REASONING)\n",
        "        \n",
        "        bert_train.class2idx_pubmedqa_label()\n",
        "        bert_test.class2idx_pubmedqa_label()\n",
        "\n",
        "        folds_idx = get_pubmedqa_fold_id(DATAPATH, DATASET)\n",
        "\n",
        "        model = my_downstream(bert_train.get_features(),bert_train.get_labels(LABELS), # Not going to be used\n",
        "                              bert_test.get_features(),bert_test.get_labels(LABELS), # Not going to be used\n",
        "                              bert_train.get_features(),bert_train.get_labels(LABELS))\n",
        "\n",
        "        temp_path2 = os.path.join(temp_path,pretrain_model,\"reason_True\")\n",
        "        LIST_MODEL = os.listdir(temp_path2)\n",
        "        \n",
        "        print()\n",
        "        print()\n",
        "        print_log(\"Ensemble pretrain LIST_MODEL:\",LIST_MODEL)\n",
        "        for group_model in LIST_MODEL:\n",
        "            temp_df = bert_test.df_BERT.copy()\n",
        "            temp_path3 = os.path.join(temp_path2,group_model)\n",
        "            LIST_FOLDS = os.listdir(temp_path3)\n",
        "\n",
        "            print()\n",
        "            print()\n",
        "            print_log(\"Ensemble pretrain LIST_FOLDS:\",str(len(LIST_FOLDS)),LIST_FOLDS)\n",
        "            for downsteam_model in LIST_FOLDS:\n",
        "                print_log(\"FULL PATH:\",temp_path3,downsteam_model)\n",
        "                model.load_multiclass_nn(D_in = 768, \n",
        "                                          n_classes = 3, \n",
        "                                          model_path = os.path.join(temp_path3,downsteam_model))\n",
        "\n",
        "                # print(model)\n",
        "                # TEST\n",
        "                _,predict_y = model.predict()\n",
        "                list_results.append(predict_y)\n",
        "\n",
        "                all_pred_df[group_model+\"_\"+downsteam_model] = pd.Series(predict_y)\n",
        "                temp_df['prediction'] = pd.Series(predict_y)\n",
        "                class_report, confusion_matrix_df = my_evaluator.eval_pubmedqa(temp_df)\n",
        "                temp_df.rename(columns={'prediction': group_model+\"_\"+downsteam_model},inplace=True)\n",
        "                list_acc.append(class_report['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "    majority_df = all_pred_df.apply(pd.Series.value_counts, axis=1).fillna(0)\n",
        "    # majority_df\n",
        "    maxValuesObj = majority_df.idxmax(axis=1)\n",
        "    maxValuesObj\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    print_log(\"Final Results of\",len(list_results),\"models\",log_type='Success')\n",
        "    # ensemble_res = sum(list_results)\n",
        "    # ensemble_res = ensemble_res/np.amax(ensemble_res) # Majority Vote\n",
        "    # # ensemble_res[ensemble_res>=1] = 1 # Only 1 is positive\n",
        "\n",
        "    temp_df = bert_test.df_BERT.copy()\n",
        "    temp_df['prediction'] = maxValuesObj\n",
        "    class_report, confusion_matrix_df = my_evaluator.eval_pubmedqa(temp_df)\n",
        "    print(confusion_matrix_df)\n",
        "    print(class_report)\n",
        "\n",
        "    return list_acc,all_pred_df"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1m6MVT6Khtv"
      },
      "source": [
        "#### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY7Gh_01Kgj9"
      },
      "source": [
        "TARGET_LABEL = ['label']\n",
        "TARGET_DATASET = \"pubmedqa\" # \"dat_hoc\",\"dat_semi\"\n",
        "TARGET_PATH = '/content/drive/MyDrive/MinorThesis/'\n",
        "\n",
        "MODEL_GROUP = \"1_pubmedbert\"\n",
        "\n",
        "list_acc,temp_df = run_pubmedqa_ensemble(TARGET_PATH,TARGET_DATASET,\n",
        "                             MODEL_GROUP = MODEL_GROUP,\n",
        "                             LABELS = TARGET_LABEL,\n",
        "                             TOKEN_SIZE=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNabRSHveVWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "7019c460-3aac-473b-8bc1-c22188c1a3ab"
      },
      "source": [
        "temp_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>20211008_13-01-09_model_fold_0.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_1.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_2.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_3.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_4.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_5.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_6.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_7.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_8.pt</th>\n",
              "      <th>20211008_13-01-09_model_fold_9.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_0.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_1.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_2.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_3.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_4.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_5.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_6.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_7.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_8.pt</th>\n",
              "      <th>20211008_13-21-15_model_fold_9.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_0.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_1.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_2.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_3.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_4.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_5.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_6.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_7.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_8.pt</th>\n",
              "      <th>20211008_12-33-17_model_fold_9.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_0.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_1.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_2.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_3.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_4.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_5.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_6.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_7.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_8.pt</th>\n",
              "      <th>20211008_12-10-17_model_fold_9.pt</th>\n",
              "      <th>...</th>\n",
              "      <th>20211008_13-25-16_model_fold_0.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_1.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_2.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_3.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_4.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_5.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_6.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_7.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_8.pt</th>\n",
              "      <th>20211008_13-25-16_model_fold_9.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_0.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_1.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_2.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_3.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_4.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_5.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_6.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_7.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_8.pt</th>\n",
              "      <th>20211008_12-17-58_model_fold_9.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_0.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_1.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_2.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_3.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_4.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_5.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_6.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_7.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_8.pt</th>\n",
              "      <th>20211008_12-57-07_model_fold_9.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_0.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_1.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_2.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_3.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_4.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_5.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_6.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_7.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_8.pt</th>\n",
              "      <th>20211008_13-33-19_model_fold_9.pt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     20211008_13-01-09_model_fold_0.pt  ...  20211008_13-33-19_model_fold_9.pt\n",
              "0                                    2  ...                                  2\n",
              "1                                    2  ...                                  2\n",
              "2                                    0  ...                                  0\n",
              "3                                    2  ...                                  2\n",
              "4                                    2  ...                                  2\n",
              "..                                 ...  ...                                ...\n",
              "495                                  0  ...                                  0\n",
              "496                                  2  ...                                  2\n",
              "497                                  1  ...                                  1\n",
              "498                                  2  ...                                  1\n",
              "499                                  0  ...                                  0\n",
              "\n",
              "[500 rows x 100 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiifAePU9LBd"
      },
      "source": [
        "### Fine-tuned BioASQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRmwPBv5KLT6"
      },
      "source": [
        "#### Assisting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME7jZIwx9KCV"
      },
      "source": [
        "# HoC\n",
        "def run_bioasq_dsgenerator(DATAPATH, DATASET, LABELS=['label'], PRETRAIN_MODEL = 'bert-base-uncased', TOKEN_SIZE = 128, SHIFT_LEVEL = None , LEARNING_RATE = 1e-5, BATCH_SIZE = 32, N_ITER=3000):\n",
        "    print_log(\"Run Generator\",\"Function\")\n",
        "    \n",
        "    # UNIQUE IDENTIFIER USING\n",
        "    sttime = datetime.now().strftime('%Y%m%d_%H-%M-%S')\n",
        "\n",
        "    bert_train, bert_test, bert_valid = transform_dataset(DATAPATH = DATAPATH,\n",
        "                                                          DATASET = DATASET,\n",
        "                                                          PRETRAIN_MODEL = PRETRAIN_MODEL,\n",
        "                                                          SHIFT_LEVEL = SHIFT_LEVEL,\n",
        "                                                          TOKEN_SIZE = TOKEN_SIZE)\n",
        "    bert_train.class2idx_bioasq_label()\n",
        "    bert_valid.class2idx_bioasq_label()\n",
        "    bert_test.class2idx_bioasq_label()\n",
        "\n",
        "\n",
        "    # # TRAINING\n",
        "    model, train_loss, valid_loss = train_linear_model(bert_train, bert_test, bert_valid,\n",
        "                               LABELS, LEARNING_RATE, BATCH_SIZE, N_ITER)\n",
        "  \n",
        "    _,predict_y = model.predict()\n",
        "\n",
        "    temp_df = bert_test.df_BERT.copy()\n",
        "    temp_df['prediction'] = pd.Series(predict_y)\n",
        "    class_report, confusion_matrix_df = my_evaluator.eval_bioasq(temp_df)\n",
        "\n",
        "    # result = {}\n",
        "    # result['dataset'] = DATASET\n",
        "    # result['labels'] = LABELS\n",
        "    \n",
        "    # result['pretrain_model'] = PRETRAIN_MODEL + '-tks' + str(TOKEN_SIZE)\n",
        "    # result['downstream_model'] = model.get_model_name()\n",
        "    # result['downstream_model_savepoint'] = \"model_\"+sttime+\".pt\"\n",
        "    \n",
        "    # result['recall'] = r\n",
        "    # result['precision'] = p\n",
        "    # result['f1score'] = f1\n",
        "\n",
        "    # result['best_iter'] = model.best_iter\n",
        "    \n",
        "    # result['SHIFT_LEVEL'] = SHIFT_LEVEL\n",
        "    # result['LEARNING_RATE'] = LEARNING_RATE\n",
        "    # result['BATCH_SIZE'] = BATCH_SIZE\n",
        "    \n",
        "    # # result['hyper_param'] = hp \n",
        "    # # result['predict_y'] = predict_y\n",
        "\n",
        "    # # SAVING SECTION\n",
        "    # temp_path_model = os.path.join(DATAPATH,\"models\",DATASET,PRETRAIN_MODEL)\n",
        "    # temp_path_result = os.path.join(DATAPATH,\"results\",DATASET,PRETRAIN_MODEL)\n",
        "\n",
        "    # Path(temp_path_model).mkdir(parents=True, exist_ok=True)\n",
        "    # Path(temp_path_result).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # # SAVE MODEL\n",
        "    # torch.save(model.best_model.state_dict(), os.path.join(temp_path_model,\"model_\"+sttime+\".pt\"))\n",
        "\n",
        "    # res_df = pd.DataFrame(result.items(), columns=['key', 'result']).set_index('key')\n",
        "    # res_df.to_json(os.path.join(temp_path_result,\"result_\"+sttime+\".json\"))\n",
        "\n",
        "    # # SAVE PLOT\n",
        "    # plt.plot(train_loss, label=\"train\")\n",
        "    # plt.plot(valid_loss, label=\"valid\")\n",
        "    # plt.title(PRETRAIN_MODEL+\"-\"+DATASET+\"-\"+str(TOKEN_SIZE))\n",
        "    # plt.suptitle(str(BATCH_SIZE)+\"-\"+str(LEARNING_RATE))\n",
        "    # plt.ylabel('loss')\n",
        "    # plt.legend()\n",
        "    # plt.savefig(os.path.join(temp_path_result,\"result_\"+sttime+\".png\"))\n",
        "\n",
        "    # print_log(\"\",log_type=\"----------\")\n",
        "    # # return predict_y\n",
        "    # return result\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiJERqyCKP7W"
      },
      "source": [
        "#### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK2idJhE9f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "935f1dee-efdd-4602-fb7b-68cdf2bc7071"
      },
      "source": [
        "TARGET_LABEL = 'label'\n",
        "TARGET_DATASET = \"BioASQ\" # \"dat_hoc\",\"dat_semi\"\n",
        "TARGET_PATH = '/content/drive/MyDrive/MinorThesis/'\n",
        "PRETRAIN_MODEL = 'biobert-base-cased'\n",
        "N_ITER=1000\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-5\n",
        "SHIFT_LEVEL=None\n",
        "\n",
        "\n",
        "res = run_bioasq_dsgenerator(TARGET_PATH,TARGET_DATASET,TARGET_LABEL,\n",
        "                        TOKEN_SIZE=512, PRETRAIN_MODEL=PRETRAIN_MODEL, \n",
        "                        LEARNING_RATE = LEARNING_RATE, BATCH_SIZE = BATCH_SIZE,\n",
        "                        N_ITER = N_ITER, SHIFT_LEVEL=SHIFT_LEVEL)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Run Generator Function\n",
            "[Info] Try loading data from cache\n",
            "[Info] Train file exist: False ( /content/drive/MyDrive/MinorThesis/datasets/transformed/BioASQ/biobert-base-cased/token_length_512/train.csv )\n",
            "[Info] Valid file exist: False ( /content/drive/MyDrive/MinorThesis/datasets/transformed/BioASQ/biobert-base-cased/token_length_512/valid.csv )\n",
            "[Info] Test file exist: False ( /content/drive/MyDrive/MinorThesis/datasets/transformed/BioASQ/biobert-base-cased/token_length_512/test.csv )\n",
            "[Info] Transform Data \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-088bf32fb9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mTOKEN_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRETRAIN_MODEL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRETRAIN_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         N_ITER = N_ITER, SHIFT_LEVEL=SHIFT_LEVEL)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-1f71424e7644>\u001b[0m in \u001b[0;36mrun_bioasq_dsgenerator\u001b[0;34m(DATAPATH, DATASET, LABELS, PRETRAIN_MODEL, TOKEN_SIZE, SHIFT_LEVEL, LEARNING_RATE, BATCH_SIZE, N_ITER)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                           \u001b[0mPRETRAIN_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPRETRAIN_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                           \u001b[0mSHIFT_LEVEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHIFT_LEVEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                           TOKEN_SIZE = TOKEN_SIZE)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mbert_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass2idx_bioasq_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbert_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass2idx_bioasq_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-ad6d79c0bf62>\u001b[0m in \u001b[0;36mtransform_dataset\u001b[0;34m(DATAPATH, DATASET, PRETRAIN_MODEL, TOKEN_SIZE, SHIFT_LEVEL, FORCE)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# TO DO : Modify this if not HoC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'filename_line'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'filename_line'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdf_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'filename_line'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5153\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             raise ValueError(\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 4 elements, new values have 3 elements"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrWxcSQaP2iC"
      },
      "source": [
        "res.df_BERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyDwIBrK8ryn"
      },
      "source": [
        "## Model Results Read "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDwre6lp-KgS"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6ZTeWq7uhKL"
      },
      "source": [
        "TARGET_PATH = '/content/drive/MyDrive/MinorThesis/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fah3fDza-H04"
      },
      "source": [
        "# temp_list = []\n",
        "# datasets = os.listdir(TARGET_PATH+\"results\")\n",
        "# print(datasets)\n",
        "# for ds in datasets:\n",
        "#     files = os.listdir(TARGET_PATH+\"results/\"+ds)\n",
        "#     # print(arr2)\n",
        "#     for f in files:\n",
        "#         print(TARGET_PATH+\"results/\"+ds+\"/\"+f)\n",
        "#         try:\n",
        "#             a = pd.read_json(TARGET_PATH+\"results/\"+ds+\"/\"+f)\n",
        "#             a = a.transpose()\n",
        "#             a.index = [f]\n",
        "#             temp_list.append(a)\n",
        "#         except:\n",
        "#             print(\"error\")\n",
        "#             pass\n",
        "# temp_res = pd.concat(temp_list, sort=False)\n",
        "# # temp_res.drop(columns='predict_y',inplace=True) # This cause error when display result\n",
        "# # temp_res.drop_duplicates(keep='last',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk9fCMvfTjkt"
      },
      "source": [
        "temp_res = temp_res[['dataset','pretrain_model','hyper_param','f1score','precision','recall']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW7PlUMYScMm"
      },
      "source": [
        "\n",
        "# temp_res.drop(columns='predict_y',inplace=True)\n",
        "# temp_res.drop(columns='labels',inplace=True)\n",
        "temp_res.drop_duplicates(keep='last',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHB1e9RM_PmU"
      },
      "source": [
        "# Table 1 : Show comparison between different type of BERT\n",
        "# ONLY Original BERT IS WORST!!!\n",
        "temp_res[(temp_res.dataset=='blurb_hoc')].sort_values(['f1score'], ascending = False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9281j_J_eBY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}